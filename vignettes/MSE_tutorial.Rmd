---bui
title: "Tutorial: cross-validation for single cell RNA-seq data via count splitting" 
output: rmarkdown::html_vignette
bibliography: latent.bib
vignette: >
  %\VignetteIndexEntry{Tutorial: cross-validation for single cell RNA-seq data via count splitting}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      collapse=TRUE, fig.width=8, fig.align="center")
```

In this tutorial, we use simple simulated datasets to show how to use count splitting to do cross-validation for unsupervised learning. Make sure that the packages below are installed, and then proceed with loading the packages. 

```{r}
library(countsplit)
library(tidyverse)
library(Matrix)
library(lemon)
```

We start by generating simple data from a negative binomial distribution. The data has three true clusters $(K^*=3)$. We generate data with only two genes ($p=2$) so that we can visualize the clusters more easily. Throughout this document, our goal is to estimate the true number of clusters $K^*$. 

```{r}
library(tidyverse)
set.seed(1)
n=200
p=2
lambda <- matrix(exp(2.5), nrow=n, ncol=p, byrow = TRUE)
clusters <- sample(1:3, size=n, replace=TRUE)
lambda[clusters==2,1] <-  exp(5)
lambda[clusters==3,2] <-  exp(0.1)
true.overdisps <- c(3,6)
X <- sapply(1:p, function(u) rnbinom(length(lambda[,u]), mu=lambda[,u], size= true.overdisps[u]))
ggplot(data=NULL, aes(x=X[,1]+1, y=X[,2]+1, col=as.factor(clusters)))+
  geom_point()+
  scale_x_log10()+
  scale_y_log10()+
  theme_bw()+
  labs(col="True Cluster")+
  xlab("Gene 1 (log scale)")+ ylab("Gene 2 (log scale)")
```

# Naive method

In order to estimate $K^*$, we try out models with different numbers of clusters $k$ ranging from $1$ to $10$, so as to see which model best fits the observed data. Unfortunately, if we estimate the clusters and evaluate the clusters on the same data, models with more clusters (i.e. more complexity) will always appear better. Thus, our loss function curve decreases monotonically with the number of clusters, and we cannot simply pick the value of $k$ that minimizes the loss function. We demonstrate this issue below. 

We will use within-cluster sum of squared errors (SSE) as our loss function. We implement this loss function here. Note that the within-cluster SSE is computed on a log scale. 

```{r}
cluster.sse <- function(trainDat, testDat, clusters.est, eps.train) {
  totSS <- 0
  for (lab in unique(clusters.est)) {
    if (sum(clusters.est==lab) > 1) {
    clustdat.test <- testDat[clusters.est==lab,]
    clustdat.train <- trainDat[clusters.est==lab,]
    colmeansTrain <- apply(clustdat.train, 2, mean)
    pred.means <- 1/eps.train*colmeansTrain
    ss <- apply(1/(1-eps.train)*clustdat.test, 1,  function(u) sum((log(u+1)-log(pred.means+1))^2))
    totSS <- totSS+sum(ss)
    }
    }
  return(totSS)
}
```

We first consider the naive method, which estimates clusters using all of the data, and then computes the SSE using all of the data. In the context of the function above, this means that ``trainDat=testDat=X``. 

```{r}
set.seed(2)
naive.res <- rep(NA, 10)
for (k in 1:10) {
  clusters.est <- kmeans(log(X+1), centers=k)$cluster
  naive.res[k] <- cluster.sse(X,X,clusters.est, 0.5)
}
naive.res
```

We normalize the SSE results such that they lie between $0$ and $1$. This will later facilitate comparisons between methods. We then ploot the results. As expected, this naive method leads to a within-cluster SSE that decreases monotonically with $k$, and thus leaves no clear strategy for estimating $K^*$. 

```{r}
naive.res.norm <- (naive.res - min(naive.res))/(max(naive.res)-min(naive.res))
ggplot(data=NULL)+
  geom_pointline(aes(x=1:10, y=naive.res.norm, col="Naive"))+
  theme_bw()+
  ylab("Within-cluster SSE")+
  xlab("Number of cluster (k)")+
  geom_vline(aes(xintercept=3))+
  labs(col="Method")+
  scale_x_continuous(breaks=0:11)
```

# Count splitting (two folds)

Splitting our data into a training set and a test set can help us avoid this issue. 

We first consider Poisson count splitting. We note that, since the data are not actually Poisson distributed, we do not expect Poisson count splitting to solve our problem. 

```{r}
set.seed(5)
poisSplit <- countsplit(X)
Xtrain.pois <- poisSplit[[1]]
Xtest.pois <- poisSplit[[2]]
pois.res <- rep(NA, 10)
for (k in 1:10) {
  clusters.est <- kmeans(log(Xtrain.pois+1), centers=k)$cluster
  pois.res[k] <- cluster.sse(Xtrain.pois,Xtest.pois,clusters.est, 0.5)
}
pois.res.norm <- (pois.res - min(pois.res))/(max(pois.res)-min(pois.res))
ggplot(data=NULL)+
  geom_pointline(aes(x=1:10, y=naive.res.norm, col="Naive"))+
  geom_pointline(aes(x=1:10, y=pois.res.norm, col="Poisson count splitting"))+
  theme_bw()+
  ylab("Within-cluster SSE")+
  xlab("Number of cluster (k)")+
  geom_vline(aes(xintercept=3))+
  labs(col="Method")+
  scale_x_continuous(breaks=0:11)+
  theme_bw()
```

If we knew the true value of the overdispersion parameters that generated our data, we could solve this problem by applying negative binomial count splitting with these known values. For this simulated dataset, we do know the true values, and so we can consider this option. We see that, unlike the other two options, negative binomial count splitting leads to a loss function that is actually minimized at $k=3$, which means that we correctly estimate $K^*$. 

```{r}
set.seed(3)
knownSplit <- countsplit(X, overdisps=true.overdisps)
Xtrain.known <- knownSplit[[1]]
Xtest.known <- knownSplit[[2]]
known.res <- rep(NA, 10)
for (k in 1:10) {
  clusters.est <- kmeans(log(Xtrain.known+1), centers=k)$cluster
  known.res[k] <- cluster.sse(Xtrain.known,Xtest.known,clusters.est, 0.5)
}
known.res.norm <- (known.res - min(known.res))/(max(known.res)-min(known.res))
ggplot(data=NULL)+
  geom_pointline(aes(x=1:10, y=naive.res.norm, col="Naive"))+
  geom_pointline(aes(x=1:10, y=pois.res.norm, col="Poisson count splitting"))+
  geom_pointline(aes(x=1:10, y=known.res.norm, col="NB count splitting"))+
  geom_vline(xintercept=3)+
  theme_bw()+
  ylab("Within-cluster SSE")+
  xlab("Number of cluster (k)")+
  geom_vline(aes(xintercept=3))+
  labs(col="Method")+
  scale_x_continuous(breaks=0:11)+
  theme(legend.text = element_text(size=10))+
  theme_bw()
```

In reality, we would need to use estimated values for the overdispersion parameters. In this toy setting with only two genes, estimating the overdispersion parameters will be difficult. For large datasets, packages such as ``sctransform`` obtain reasonable estimates of overdispersion parameters by making use of the fact that most genes tend to be null (not differentially expressed across any cells) and that genes with similar average experssion levels have similar overdispersion parameters. We will explore the matter of estimated overdispersion parameters in future tutorials. 

```{r}
summary(MASS::glm.nb(X[,1]~1))$theta
summary(MASS::glm.nb(X[,2]~1))$theta
```

# Cross validation via count splitting

We can improve on the previous analysis by replacing a single train/test split with cross validation. We do this in the negative binomial setting, as this is the correct setting for this analysis. 

We first create five identically distributed folds of data.

```{r}
set.seed(10)
folds <- 5
partition.known <-  countsplit(X, folds=folds, overdisps=true.overdisps)
```

We know loop through each fold of data. For each fold, we estimate clusters on all the data that are not in that fold, and we evaluate the MSE using the held out fold.

```{r}
knownRes <- matrix(NA, nrow=folds, ncol=10)
for (fold in 1:folds) {
        testDat <- partition.known[[fold]]
        trainDat <- X - testDat
         for (j in 1:10) {
             clusters.train <- kmeans(log(trainDat+1), centers=j, nstart=10)$cluster
              knownRes[fold,j] <- cluster.sse(trainDat, testDat, clusters.train, 1-1/folds)
         }
}
```

The total score for each attempted number of clusters ($k$) is taken to be the average MSE across the 5 folds. We once again normalize to facilitate comparison with other methods. 

```{r}
MSEs <- colMeans(knownRes)
MSEs.norm <- (MSEs-min(MSEs))/(max(MSEs)-min(MSEs))
ggplot(data=NULL)+
  geom_pointline(aes(x=1:10, y=naive.res.norm, col="Naive"))+
  geom_pointline(aes(x=1:10, y=pois.res.norm, col="Poisson count splitting"))+
  geom_pointline(aes(x=1:10, y=known.res.norm, col="NB count splitting"))+
  geom_pointline(aes(x=1:10, y=MSEs.norm, col="NB cross validation"))+
  geom_vline(xintercept=3)+
  theme_bw()+
  ylab("Within-cluster SSE")+
  xlab("Number of cluster (k)")+
  geom_vline(aes(xintercept=3))+
  labs(col="Method")+
  scale_x_continuous(breaks=0:11)+
  theme(legend.text = element_text(size=10))+
  theme_bw()
```

Looking at the results, we can see that NB cross validation also leads to a loss function that is minimized at the correct number of clusters. Across many repeated trials, we expect NB cross validation to select the correct number of clusters more often than NB count splitting, as aggregating the loss function across folds helps reduce the variance of the loss function.


# Visualizing what is going on

A nice thing about working with data in two dimensions is that we can visualize our data along with the true clusters. 


